#RL 

> [!WARNING] 未完成
> 把中间涉及的证明推导一遍


- 强化学习的终极目标是**寻找最优策略**
- 改进策略的例子：
	- 书中给出了一个例子，即在网格世界中寻找奖励最大的路线，我们通过动作价值来评估策略，根据动作价值=动作奖励+转移到的状态的价值，所以第一步要根据当前策略算出所有状态的价值，然后再加上动作价值得到所有动作价值，那么对于当前所处的状态，选择所有动作中价值最大的就是最优策略
	- 核心，先算状态价值，再算动作价值，然后最大化动作价值来改进策略
- **最优策略与最优状态值**：策略$\pi^*$为最优策略的条件，即对于任意状态$s \in \mathcal{S}$（$\mathcal{S}$为状态集合 ）和任意其他策略$\pi$，都有$v_{\pi^*}(s) \geq v_{\pi}(s)$（$v_{\pi}(s)$表示策略$\pi$在状态$s$下的状态值 ）。
---------
- 问题：
	1. **存在性**：探讨是否存在满足定义的最优策略 。
	2. **唯一性**：探究符合条件的最优策略是仅有一个，还是可能有多个 。
	3. **随机性**：考察最优策略的性质，是确定性（给定状态，策略确定选某一行动）还是随机性（给定状态，策略以概率分布选行动 ）。
	4. **算法**：询问用于求解最优策略和对应最优状态值的具体方法，像强化学习里的价值迭代、策略迭代等算法常涉及 。
- 贝尔曼最优方程 $BOE$：
	-  对于每个状态 $s$ ：
		- 这里 $v (s), v (s')$ 是待求解的未知量；$\pi (s)$ 表示状态 $s$ 的策略；$\Pi (s)$ 是在状态 $s$ 所有可能策略的集合
		- 右边是个优化问题，右边是各个状态动作价值的期望和，如果要最大化，那么就直接让最大的状态动作价值的发生概率为 1 即可
		- $$

\begin{align*}

v(s)&=\max_{\pi(s)\in\Pi(s)}\sum_{a\in\mathcal{A}}\pi(a|s)\left(\sum_{r\in\mathcal{R}}p(r|s,a)r + \gamma\sum_{s'\in\mathcal{S}}p(s'|s,a)v(s')\right)\\

&=\max_{\pi(s)\in\Pi(s)}\sum_{a\in\mathcal{A}}\pi(a|s)q(s,a)

\end{align*}

$$
    - 对于所有所有状态写成矩阵向量形式：
	    - $$v = \max_{\pi \in \varPi} (r_\pi + \gamma P_\pi v)$$
	    - 令 $f(v) \triangleq \max_{\pi \in \varPi} (r_\pi + \gamma P_\pi v)$ 则： $$v = f(v)$$
	- 为了回答上面的问题，可证明 $f(v)$ 符合压缩映射定理，于是有以下性质
		- 存在性：一定存在一个不动点$x^*$满足$f(x^*) = x^*$。
		- 唯一性：不动点$x^*$是唯一的。
		- 算法：考虑迭代算法$$x_{k + 1} = f(x_k),$$
			其中 $k = 0,1,2,\dots$。给定任意一个初始值 $x_0$，当 $k \to \infty$ 时，$x_k \to x^*$，且收敛过程具有指数收敛速度。
		- 这个方程式最优策略下的贝尔曼方程，根据以上直到它的解是唯一的
	- 接着就是证明这个唯一解是最优解（得证，看书）
	- 最后是说明怎么得到最优策略，就是通过贪婪算法，每次策略选择动作价值最大的动作，将其变成确定性概率
	- 所以上面的思路就是，证明最优价值和最优策略是同时出现的，最优价值是唯一的，可以通过最优策略求解

























求解最优状态值\(v^*\)：如果\(v^*\)是贝尔曼最优方程的解，那么它满足

\[v^* = f(v^*) = \max_{\pi \in \varPi} (r_\pi + \gamma P_\pi v^*).\]

显然，\(v^*\)是一个不动点。根据压缩映射定理，有如下重要结论。

**定理3.3** (存在性、唯一性、算法)。贝尔曼最优方程\(v = f(v) = \max_{\pi \in \varPi} (r_\pi + \gamma P_\pi v)\)始终存在唯一解\(v^*\)，该解可以通过如下迭代算法求解：

\[v_{k + 1} = f(v_k) = \max_{\pi \in \varPi} (r_\pi + \gamma P_\pi v_k),\quad k = 0, 1, 2, \dots\]

对任意给定的\(v_0\)，当\(k \to \infty\)时，\(v_k\)以指数速度收敛至\(v^*\)。

因为\(f(v)\)是一个压缩映射，所以上面的定理可以直接由压缩映射定理得到。上面的定理很重要，因为它能回答一系列重要的基础问题。

- 存在性：贝尔曼最优方程的解总是存在的。

- 唯一性：贝尔曼最优方程的解总是唯一的。

- 算法：贝尔曼最优方程可以通过定理3.3中的迭代算法求解。此迭代算法有一个名字——值迭代。该算法的具体实施步骤将在第4章详细介绍，本章主要关注贝尔曼最优方程的基本性质。