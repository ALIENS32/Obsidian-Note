# 概念

- 目的：将输入文本分成一个个次元，每个次元拥有相对完整和独立的语义
- 分词粒度：
	- 词：无法表示英语这类语言，超出词典的词无法表示（OOV 问题）
	- 字符：词表小，但是会导致分出的序列过长
	- 子词：生僻词被切成子词来表示，压缩空间；平衡上述两者，现在广泛使用

# 算法

## BPE

BPE（字节对编码）是一种用于子词单元处理的方法，核心是从基础小词表出发，不断合并高频连续token对生成新词表，能平衡词汇表大小与编码步数，但存在基于贪心替换、无法提供带概率分词结果及解码歧义等问题 ，其流程和特性如下：
1. **核心思想**：从基础小词表起，持续合并语料里高频连续token对来生成新token 。
2. **具体步骤**：先准备含字母、符号等的基础词表并初始化ID；再用基础词表拆分语料为最小单元；接着统计语料中单词相邻单元对频率，合并最高频的；重复合并，直到达到预设词表大小或最高频率为1 。
3. **优点**：有效平衡词汇表大小和编码步数（编码句子所需token数量，关联词表大小与粒度 ）。
4. **缺点**：基于贪心确定符号替换，无法给出带概率的多个分词结果；解码时遇歧义，同一句子可能有不同分词结果 。
（看飞书文档例子就懂了，就是不断将经常一起出现的多个基础单元合并来减少词典大小）

## BBPE

对 BPE 进行拓展，核心是从字符级扩展到字节级（基础词表用 256 字节集、UTF - 8 编码 ），优点众多，像词表减小、多语言共享好、适配多类型数据、无损压缩等，不过也存在编码序列长、计算成本高，解码易歧义需上下文辅助的缺点 。
1. **核心思想**：把BPE从字符级别拓展到字节级别，解决噪声文本或字符丰富语言（如日语、中文 ）稀有字符占用词汇表、限制紧凑性问题。
2. **具体做法**：基础词表采用256的字节集，以UTF - 8编码。
3. **优点**：效果与BPE相当但词表大幅减小；多语言间字节级子词共享性好，字符集不重叠也能迁移；可动态生成词汇表实现高效压缩，适配文本、图像等多种数据；无损压缩且可解码；压缩效果和词表大小可灵活调整 。
4. **缺点**：编码序列长度可能更长，计算成本更高；byte解码易遇歧义，需上下文和动态规划辅助解码 。

## Word Piece

从基础词表出发，通过合并互信息最大的 token 对构建词表，区别于 BPE 按频率合并，它以提升训练数据概率为导向，利用子词互信息选合并对象。

假设训练语料为 `["apple is a fruit", "banana is also a fruit"]`，目标词表大小设为 5 ，步骤如下：
1. **基础词表准备**：
	选英文 26 字母 + 空格等符号，如 `['a','b','c',…,'z',' ']` ，作为初始拆分单元。
2. **语料拆分最小单元**：
	按基础词表拆分语料，如 “apple is a fruit” 拆为 `['a','p','p','l','e',' ','i','s',' ','a',' ','f','r','u','i','t']` ；“banana is also a fruit” 拆为 `['b','a','n','a','n','a',' ','i','s',' ','a','l','s','o',' ','a',' ','f','r','u','i','t']` 。
3. **训练语言模型（unigram ）**：
	统计拆分后子词频率，训练 unigram 模型。比如统计得 `P('a')=0.2`（假设值，实际依语料精确计算 ）、`P('p')=0.05`、`P(' ')=0.1` 等，用于后续概率计算。
4. **选互信息最大的 token 对合并**：
	计算所有可能 token 对的互信息分数（公式 `score = P(t_z)/(P(t_x)P(t_y))` ，`t_z` 是合并后的子词，`t_x`、`t_y` 是待合并子词 ）。
	以 “ap” 为例：若统计得 `P('ap')=0.03` ，结合 `P('a')=0.2`、`P('p')=0.05` ，则 `score = 0.03/(0.2×0.05)=3` 。遍历所有 token 对，选分数最高的（比如 “fr” 和 “ui” 合并成 “fru” 能最大提升数据概率 ）执行合并。
5. **重复合并直到满足条件**：
	持续执行步骤 4，每次合并互信息最大的子词，直到词表大小达 5 或概率增量低于阈值。假设最终词表为 `['app','le','is','a','fru']` 。

- **优点**：平衡词表大小与 OOV 问题。比如新出现 “pineapple” ，可用已有子词 “app”“le” 组合编码，减少未登录词。
- **缺点**：
	- 对拼写错误敏感：若语料有 “aple”（正确是 “apple” ），错误拼写会干扰子词频率与互信息计算，可能生成不合理子词。
	- 前缀支持不足：遇到 “reapple” 这类带前缀的词，拆分逻辑难精准处理前缀，易产生糟糕切分。
简言之，Fast WordPiece 借互信息合并优化词表构建，在平衡词表与适配未登录词上有优势，但受拼写、前缀等场景限制，需结合额外策略（如拆分复合词、前缀 ）补足。